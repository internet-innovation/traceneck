\section{Introduction}

Internet performance has historically been summarized using a single number: ``speed'' \cite{bauer2010understanding,midoglu2018monroenettestconfigurabletooldissecting,feamster2019internetspeedmeasurementcurrent}. Despite the widespread utility, the user-perceived Quality of Experience (QoE) for many applications (e.g., video-conferencing, gaming, cloud collaboration) is governed less by peak bandwidth and more by latency under load. To address this, measurement providers have recently begun introducing ``latency under load'' (LUL) or ``responsiveness'' metrics, which attempt to capture how queuing delays increase during download and upload activity.

However, the interpretation and use of these metrics has not been standardized. For instance, Ookla defines ``working latency'' as the increase in round-trip time (RTT) under load compared to the unloaded RTT, measured during a speed test \cite{CeroWRT_speedtests}. Apple uses a different metric, called round trips per minute (RPM) under load, which counts the number of round trips completed during a fixed time interval while the connection is saturated \cite{ietf-ippm-responsiveness-07}. Further, these tests have been known to discard outliers that often correspond to glitches that users typically notice during real-time applications such as video conferencing and streaming \cite{CeroWRT_speedtests}. As a result, users and regulators are left with incomplete pictures of what causes an Internet connection to be unresponsive, and how it can be mitigated. A central, unanswered question is how traditional metrics such as throughput and latency, and new metrics such as LUL and RPM, behave in the presence or absence of active queue management (AQM) algorithms such as FQ-CoDel, which were explicitly designed to maintain low latency under load \cite{hoilandbufferbloat}.

In this paper, we investigate how the empirical distribution of modern speed test measurement results shifts when an AQM is deployed. Rather than reporting only typical throughput (e.g., mean) and latency values (e.g., $90^{th}$ percentile, median), we analyze full distributions: the tails, the spikes, and metrics similar to ``glitches per minute'' \cite{CeroWRT_speedtests} that are most relevant to real-time applications. Our goal is to empirically characterize the difference between unmanaged queues and AQM-enabled network paths, and to highlight how this difference is (or is not) reflected in widely deployed measurement platforms. By doing so, we aim to inform both test designers and network operators of the gaps between the status quo of Internet measurement and the actual experience of end-users.

\taveesh{Methods summary and contributions go here.}

\siddhant{We also need some stronger justifications for why we are doing this study. 
Maybe something like: "While AQM has been widely studied in the context of TCP performance, its impact on speedtest measurements remains underexplored.
Secondly, AQM deployment is steadily increasing (some numbers from Jason/Comcast article/any other source)
Understanding this relationship is crucial for both network operators and end-users to accurately assess and improve their internet experience."}